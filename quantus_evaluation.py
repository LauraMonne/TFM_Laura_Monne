"""
Evaluaci√≥n cuantitativa de explicabilidad usando Quantus.

Mide 5 dimensiones para varios m√©todos XAI (Grad-CAM, Grad-CAM++, IG, Saliency):
- Fidelidad      -> FaithfulnessCorrelation
- Robustez       -> AvgSensitivity
- Complejidad    -> Complexity (o Entropy)
- Aleatorizaci√≥n -> MPRT / ModelParameterRandomisation
- Localizaci√≥n   -> RegionPerturbation

Uso t√≠pico:
    python quantus_evaluation.py --dataset retina --num_samples 100 --seed 123
"""

from __future__ import annotations

import argparse
import copy
import json
import os
import random
from typing import Dict, List, Callable, Tuple

import numpy as np
import torch
from tqdm import tqdm

try:
    import quantus
except ImportError as exc:
    raise SystemExit(
        "quantus no est√° instalado. Ejecuta: pip install quantus"
    ) from exc

from prepare_data import load_datasets, get_dataset_info
from train import create_data_loaders
from xai_explanations import XAIExplainer, load_trained_model


# ============================================================
#  Reproducibilidad
# ============================================================

def set_global_seed(seed: int) -> None:
    """Establece la semilla global para reproducibilidad."""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    # Determinismo (puede reducir rendimiento)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


# ============================================================
#  Argumentos de l√≠nea de comandos
# ============================================================

# Construye el parser de argumentos.

def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Evaluaci√≥n cuantitativa de XAI con Quantus (por dataset individual)."
    )
    parser.add_argument(
        "--dataset",
        required=True,
        choices=["blood", "retina", "breast"],
        help="Dataset a evaluar: blood (8 clases), retina (5 clases) o breast (2 clases).",
    )
    parser.add_argument(
        "--model_path",
        type=str,
        default=None,
        help="Ruta al checkpoint entrenado. Si no se especifica, usa results/best_model_{dataset}.pth",
    )
    parser.add_argument(
        "--data_dir",
        default="./data",
        help="Directorio con los datasets MedMNIST.",
    )
    parser.add_argument(
        "--num_samples",
        type=int,
        default=30,
        help="N√∫mero de muestras del set de test a evaluar.",
    )
    parser.add_argument(
        "--batch_size",
        type=int,
        default=1,
        help="Batch size al recorrer el conjunto de test.",
    )
    parser.add_argument(
        "--device",
        default="cuda" if torch.cuda.is_available() else "cpu",
        help="cpu o cuda.",
    )
    parser.add_argument(
        "--methods",
        nargs="+",
        default=["gradcam", "gradcampp", "integrated_gradients", "saliency"],
        help="M√©todos XAI a evaluar (gradcam, gradcampp, integrated_gradients, saliency).",
    )
    parser.add_argument(
        "--output",
        type=str,
        default=None,
        help="Ruta de guardado para los resultados. Si no se especifica, usa outputs/quantus_metrics_{dataset}.json",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=123,
        help="Seed global para reproducibilidad.",
    )
    return parser.parse_args()


# ============================================================
#  Utilidades de datos
# ============================================================

# Recopila muestras del conjunto de test.
# Devuelve un tensor BCHW (batch, channels, height, width).
# y un tensor BHWC (batch, height, width, channels).
def collect_samples(test_loader, num_samples: int, device: torch.device) -> tuple[torch.Tensor, torch.Tensor]:
    """Recopila x_batch, y_batch del conjunto de test."""
    xs: List[torch.Tensor] = []
    ys: List[torch.Tensor] = []
    with torch.no_grad():
        for idx, (data, target) in enumerate(tqdm(test_loader, desc="Recolectando muestras")):
            if idx >= num_samples:
                break
            xs.append(data)
            ys.append(target)
    if not xs:
        raise RuntimeError("No se encontraron muestras. Ajusta num_samples.")
    x_batch = torch.cat(xs, dim=0).to(device)
    y_batch = torch.cat(ys, dim=0).to(device)
    return x_batch, y_batch

# Convierte un tensor BCHW a BHWC para Quantus.
def to_numpy_bchw(tensor_batch: torch.Tensor) -> np.ndarray:
    """Convierte un tensor BCHW a NumPy BCHW (sin cambiar el orden de ejes)."""
    return tensor_batch.detach().cpu().numpy()


# ============================================================
#  Sanitizaci√≥n / normalizaci√≥n de atribuciones
# ============================================================

def sanitize_attribution(attr: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:
    """
    Sanitiza y normaliza atribuciones para mejorar estabilidad num√©rica.
    
    - Fuerza float32 para consistencia
    - Reemplaza nan/inf por 0
    - Normaliza por muestra a [0,1] (min-max) para evitar mapas constantes raros
    
    Args:
        attr: Tensor de atribuciones (C, H, W) o (B, C, H, W)
        eps: Tolerancia para detectar mapas constantes
        
    Returns:
        Tensor sanitizado y normalizado
    """
    attr = attr.to(dtype=torch.float32)
    attr = torch.nan_to_num(attr, nan=0.0, posinf=0.0, neginf=0.0)
    
    # Si todo es cero (mapa vac√≠o), devolvemos tal cual
    if torch.all(attr == 0):
        return attr
    
    # Normalizaci√≥n min-max por tensor (C,H,W) o (B,C,H,W)
    if attr.ndim == 3:  # (C, H, W)
        mn = torch.min(attr)
        mx = torch.max(attr)
        if (mx - mn).abs() < eps:
            # Mapa constante -> lo dejamos a ceros
            return torch.zeros_like(attr)
        attr = (attr - mn) / (mx - mn + eps)
    elif attr.ndim == 4:  # (B, C, H, W) - normalizar por muestra
        for b in range(attr.shape[0]):
            sample = attr[b]
            mn = torch.min(sample)
            mx = torch.max(sample)
            if (mx - mn).abs() < eps:
                attr[b] = torch.zeros_like(sample)
            else:
                attr[b] = (sample - mn) / (mx - mn + eps)
    else:
        # Formato no soportado, devolver tal cual
        return attr
    
    return attr


# ============================================================
#  Atribuciones XAI (reutiliza XAIExplainer)
# ============================================================

# Expande un heatmap HxW a CxHxW repitiendo por canal.
def expand_heatmap_to_channels(heatmap: np.ndarray, channels: int) -> torch.Tensor:
    """Expande un heatmap HxW a CxHxW repitiendo por canal."""
    if heatmap.ndim != 2:
        raise ValueError("El heatmap debe ser 2D.")
    tensor = torch.tensor(heatmap, dtype=torch.float32)
    tensor = tensor.unsqueeze(0).repeat(channels, 1, 1)  # (C, H, W)
    return tensor


def compute_attributions(
    explainer: XAIExplainer,
    x_batch: torch.Tensor,
    preds: torch.Tensor,
    method: str,
) -> torch.Tensor:
    """
    Genera atribuciones para todo el batch usando el m√©todo especificado.
    Devuelve un tensor BCHW (batch, channels, height, width).
    """
    attributions: List[torch.Tensor] = []
    for idx in tqdm(range(len(x_batch)), desc=f"Atribuciones {method}"):
        sample = x_batch[idx : idx + 1]
        target_class = int(preds[idx].item())
        try:
            if method == "gradcam":
                result = explainer.generate_gradcam(sample, target_class, save_path=None)
                if result is None:
                    raise RuntimeError("Grad-CAM retorn√≥ None")
                _, heatmap = result
                attr = expand_heatmap_to_channels(heatmap, sample.shape[1])
            elif method == "gradcampp":
                result = explainer.generate_gradcampp(sample, target_class, save_path=None)
                if result is None:
                    raise RuntimeError("Grad-CAM++ retorn√≥ None")
                _, heatmap = result
                attr = expand_heatmap_to_channels(heatmap, sample.shape[1])
            elif method == "integrated_gradients":
                result = explainer.generate_integrated_gradients(sample, target_class, save_path=None)
                if result is None:
                    raise RuntimeError("IG retorn√≥ None")
                attr = result[1][0].detach().cpu()  # (C, H, W)
            elif method == "saliency":
                result = explainer.generate_saliency_map(sample, target_class, save_path=None)
                if result is None:
                    raise RuntimeError("Saliency retorn√≥ None")
                attr = result[1][0].detach().cpu()  # (C, H, W)
            else:
                raise ValueError(f"M√©todo desconocido: {method}")
            
            # Sanitizar atribuci√≥n antes de a√±adirla
            attr = sanitize_attribution(attr)
        except Exception as err:
            print(f"‚ö†Ô∏è Error generando atribuci√≥n para muestra {idx}: {err}")
            attr = torch.zeros_like(sample[0].cpu())
        attributions.append(attr)
    return torch.stack(attributions, dim=0)  # (B, C, H, W)


# ============================================================
#  explain_func para m√©tricas que lo requieren (robustness, randomization)
# ============================================================


def build_explain_func(
    explainer: XAIExplainer,
    method: str,
    device: torch.device,
) -> Callable:
    """
    Construye una explain_func compatible con Quantus.
    Firma esperada: explain_func(model, inputs, targets, **kwargs) -> np.ndarray
    """

    def explain_func(model, inputs, targets, **kwargs):
        # inputs puede venir como np.ndarray o torch.Tensor, BCHW o BHWC
        if isinstance(inputs, np.ndarray):
            x = torch.tensor(inputs, dtype=torch.float32)
        else:
            x = inputs

        if x.ndim == 4 and x.shape[-1] in (1, 3):  # BHWC -> BCHW
            x = x.permute(0, 3, 1, 2)

        x = x.to(device)

        if isinstance(targets, np.ndarray):
            y = torch.tensor(targets, dtype=torch.long, device=device)
        else:
            y = targets.to(device)

        attributions: List[torch.Tensor] = []
        for i in range(len(x)):
            sample = x[i : i + 1]
            target_class = int(y[i].item())
            try:
                if method == "gradcam":
                    result = explainer.generate_gradcam(sample, target_class, save_path=None)
                    if result is None:
                        raise RuntimeError("Grad-CAM retorn√≥ None")
                    _, heatmap = result
                    attr = expand_heatmap_to_channels(heatmap, sample.shape[1])
                elif method == "gradcampp":
                    result = explainer.generate_gradcampp(sample, target_class, save_path=None)
                    if result is None:
                        raise RuntimeError("Grad-CAM++ retorn√≥ None")
                    _, heatmap = result
                    attr = expand_heatmap_to_channels(heatmap, sample.shape[1])
                elif method == "integrated_gradients":
                    result = explainer.generate_integrated_gradients(sample, target_class, save_path=None)
                    if result is None:
                        raise RuntimeError("IG retorn√≥ None")
                    attr = result[1][0].detach().cpu()
                elif method == "saliency":
                    result = explainer.generate_saliency_map(sample, target_class, save_path=None)
                    if result is None:
                        raise RuntimeError("Saliency retorn√≥ None")
                    attr = result[1][0].detach().cpu()
                else:
                    raise ValueError(f"M√©todo desconocido: {method}")
                
                # Sanitizar atribuci√≥n antes de a√±adirla
                attr = sanitize_attribution(attr)
            except Exception as err:
                print(f"‚ö†Ô∏è Error en explain_func para muestra {i}: {err}")
                attr = torch.zeros_like(sample[0].cpu())
            attributions.append(attr)

        # Devuelve BCHW como NumPy
        return torch.stack(attributions, dim=0).detach().cpu().numpy()

    return explain_func


# ============================================================
#  M√©tricas de Quantus
# ============================================================

# Crea un conjunto est√°ndar de m√©tricas de Quantus.
# Devuelve un diccionario con las m√©tricas.
def create_metrics() -> Dict[str, object]:
    """Crea un conjunto est√°ndar de m√©tricas de Quantus."""
    metrics: Dict[str, object] = {}

    # Fidelidad
    metrics["faithfulness"] = quantus.FaithfulnessCorrelation()

    # Robustez
    # Configuraci√≥n para evitar valores inf/nan:
    # - return_nan_when_prediction_changes=True: devuelve nan en lugar de inf cuando la predicci√≥n cambia
    # - nr_samples=30: reduce el n√∫mero de muestras para evitar problemas num√©ricos (default=200)
    # - lower_bound=0.02: ruido m√≠nimo muy peque√±o para evitar cambios de predicci√≥n
    # - upper_bound=0.15: ruido m√°ximo peque√±o para mantener predicciones estables
    # - abs=True: usa valores absolutos para evitar problemas con signos
    # - normalise=True: normaliza las explicaciones para estabilidad num√©rica
    # - similarity_func: usar correlaci√≥n en lugar de distancia euclidiana (m√°s robusta)
    metrics["robustness"] = quantus.AvgSensitivity(
        nr_samples=30,  # Reducir muestras para evitar problemas num√©ricos
        abs=True,  # Usar valores absolutos
        normalise=True,  # Normalizar para estabilidad
        lower_bound=0.02,  # Ruido m√≠nimo muy peque√±o para evitar cambios de predicci√≥n
        upper_bound=0.15,  # Ruido m√°ximo peque√±o para mantener predicciones estables
        return_nan_when_prediction_changes=True,  # Devolver nan en lugar de inf
        disable_warnings=True,  # Desactivar warnings para limpieza
    )

    # Complejidad o Entropy
    try:
        metrics["complexity"] = quantus.Complexity()
    except AttributeError:
        metrics["complexity"] = quantus.Entropy()

    # Aleatorizaci√≥n (MPRT o ModelParameterRandomisation)
    # MPRT mide c√≥mo cambian las explicaciones cuando se aleatorizan los par√°metros del modelo.
    # Valores cercanos a 1.0 indican que las explicaciones no cambian (malo - explicaciones no son sensibles).
    # Valores cercanos a 0.0 indican que las explicaciones cambian significativamente (bueno - explicaciones son sensibles).
    # 
    # PROBLEMA: Si todos los m√©todos obtienen ~1.0, puede ser que:
    # 1. La m√©trica no est√© aleatorizando correctamente los par√°metros
    # 2. Las explicaciones realmente no cambian cuando se aleatorizan par√°metros (problema de los m√©todos XAI)
    # 3. Hay un bug en c√≥mo se est√° usando la m√©trica
    #
    # SOLUCI√ìN MEJORADA: Probar configuraciones m√°s agresivas y usar m√©trica alternativa si es necesario
    try:
        RandomizationMetric = quantus.MPRT
        print("üìä Usando m√©trica MPRT para randomization")
    except AttributeError:
        RandomizationMetric = quantus.ModelParameterRandomisation
        print("üìä Usando m√©trica ModelParameterRandomisation para randomization")
    
    # Intentar configurar con par√°metros que ayuden a diferenciar m√©todos
    # Orden de intentos: de m√°s espec√≠fico a m√°s general
    randomization_metric = None
    config_attempts = [
        # Configuraci√≥n 1: Con correlaci√≥n de Spearman (sin normalizaci√≥n para m√°s variaci√≥n)
        {
            "name": "correlaci√≥n Spearman sin normalizaci√≥n",
            "params": {
                "similarity_func": quantus.similarity_func.correlation_spearman,
                "normalise": False,
                "disable_warnings": True,
            }
        },
        # Configuraci√≥n 2: Con correlaci√≥n de Spearman (con normalizaci√≥n)
        {
            "name": "correlaci√≥n Spearman + normalizaci√≥n",
            "params": {
                "similarity_func": quantus.similarity_func.correlation_spearman,
                "normalise": True,
                "disable_warnings": True,
            }
        },
        # Configuraci√≥n 3: Con correlaci√≥n de Pearson
        {
            "name": "correlaci√≥n Pearson + normalizaci√≥n",
            "params": {
                "similarity_func": quantus.similarity_func.correlation_pearson,
                "normalise": True,
                "disable_warnings": True,
            }
        },
        # Configuraci√≥n 4: Solo normalizaci√≥n
        {
            "name": "solo normalizaci√≥n",
            "params": {
                "normalise": True,
                "disable_warnings": True,
            }
        },
        # Configuraci√≥n 5: Sin normalizaci√≥n (m√°s variaci√≥n)
        {
            "name": "sin normalizaci√≥n",
            "params": {
                "normalise": False,
                "disable_warnings": True,
            }
        },
        # Configuraci√≥n 6: Por defecto
        {
            "name": "por defecto",
            "params": {}
        }
    ]
    
    for attempt in config_attempts:
        try:
            randomization_metric = RandomizationMetric(**attempt["params"])
            print(f"   ‚úì Configuraci√≥n exitosa: {attempt['name']}")
            break
        except (TypeError, AttributeError, KeyError) as e:
            continue
    
    if randomization_metric is None:
        # Si todas las configuraciones fallan, usar la m√°s b√°sica
        print("   ‚ö†Ô∏è  Todas las configuraciones fallaron, usando configuraci√≥n m√≠nima")
        randomization_metric = RandomizationMetric()
    
    metrics["randomization"] = randomization_metric

    # Localizaci√≥n
    metrics["localization"] = quantus.RegionPerturbation()

    # NOTA: Si MPRT sigue dando valores constantes (~1.0) para todos los m√©todos,
    # se puede considerar usar m√©tricas alternativas como:
    # - quantus.RandomLogit: Mide la distancia entre explicaci√≥n original y una clase aleatoria
    # - Una m√©trica personalizada que compare explicaciones con diferentes seeds
    # Sin embargo, MPRT es la m√©trica est√°ndar para randomization, as√≠ que primero
    # intentamos con las configuraciones mejoradas arriba.

    return metrics


# ============================================================
#  M√©trica alternativa de Randomization (si MPRT no funciona)
# ============================================================

def create_alternative_randomization_metric():
    """
    Crea una m√©trica alternativa de randomization basada en la variabilidad
    de las explicaciones con diferentes seeds.
    
    Esta m√©trica mide qu√© tan diferentes son las explicaciones cuando se generan
    con diferentes seeds, lo cual es un proxy para la sensibilidad a la aleatorizaci√≥n.
    """
    
    class AlternativeRandomizationMetric:
        """
        M√©trica alternativa que mide la variabilidad de las explicaciones
        generadas con diferentes seeds.
        
        Valores m√°s altos = m√°s variabilidad = mejor (las explicaciones son sensibles)
        Valores m√°s bajos = menos variabilidad = peor (las explicaciones son constantes)
        """
        
        def __init__(self, num_seeds=10):
            # Aumentar n√∫mero de seeds para m√°s sensibilidad
            self.num_seeds = num_seeds
        
        def __call__(self, model, x_batch, y_batch, explain_func, **kwargs):
            """
            Calcula la diferencia entre explicaciones del modelo original y un modelo aleatorizado.
            
            Esta m√©trica mide qu√© tan diferentes son las explicaciones cuando se comparan
            con un modelo con par√°metros completamente aleatorizados.
            
            Args:
                model: Modelo PyTorch original
                x_batch: Batch de im√°genes (B, C, H, W)
                y_batch: Batch de etiquetas
                explain_func: Funci√≥n que genera explicaciones
                **kwargs: Argumentos adicionales
            
            Returns:
                Array de scores (uno por muestra)
            """
            device = kwargs.get('device', next(model.parameters()).device)
            scores = []
            
            # Generar explicaciones con el modelo original
            expl_original = explain_func(model, x_batch, y_batch)
            
            # Crear una copia del modelo con par√°metros aleatorizados
            model_randomized = copy.deepcopy(model)
            
            # Aleatorizar todos los par√°metros del modelo
            with torch.no_grad():
                for param in model_randomized.parameters():
                    # Inicializar con valores aleatorios (similar a inicializaci√≥n normal)
                    if len(param.shape) >= 2:
                        # Para matrices (conv, linear): usar inicializaci√≥n normal
                        torch.nn.init.normal_(param, mean=0.0, std=0.1)
                    else:
                        # Para bias: usar valores peque√±os aleatorios
                        torch.nn.init.normal_(param, mean=0.0, std=0.01)
            
            model_randomized.eval()
            
            # Generar explicaciones con el modelo aleatorizado
            expl_randomized = explain_func(model_randomized, x_batch, y_batch)
            
            # Calcular diferencia entre explicaciones originales y aleatorizadas
            for i in range(len(x_batch)):
                # Obtener explicaciones para esta muestra
                exp_orig = np.array(expl_original[i]) if not isinstance(expl_original[i], np.ndarray) else expl_original[i]
                exp_rand = np.array(expl_randomized[i]) if not isinstance(expl_randomized[i], np.ndarray) else expl_randomized[i]
                
                # Normalizar cada explicaci√≥n a [0, 1]
                exp_orig_flat = exp_orig.flatten()
                exp_rand_flat = exp_rand.flatten()
                
                if exp_orig_flat.max() - exp_orig_flat.min() > 1e-8:
                    exp_orig_norm = (exp_orig_flat - exp_orig_flat.min()) / (exp_orig_flat.max() - exp_orig_flat.min())
                else:
                    exp_orig_norm = exp_orig_flat
                
                if exp_rand_flat.max() - exp_rand_flat.min() > 1e-8:
                    exp_rand_norm = (exp_rand_flat - exp_rand_flat.min()) / (exp_rand_flat.max() - exp_rand_flat.min())
                else:
                    exp_rand_norm = exp_rand_flat
                
                # Calcular distancia euclidiana entre explicaciones normalizadas
                # Mayor distancia = m√°s diferencia = mejor (las explicaciones son sensibles a la aleatorizaci√≥n)
                distance = np.linalg.norm(exp_orig_norm - exp_rand_norm)
                
                # Normalizar distancia (distancia m√°xima posible es ~sqrt(2) para vectores normalizados)
                normalized_distance = min(distance / np.sqrt(2), 1.0)
                
                # INVERTIR: MPRT mide similitud (1.0 = no cambia = malo)
                # Nuestra m√©trica mide diferencia (1.0 = mucho cambio = bueno)
                # Para ser consistente con MPRT, invertimos: score = 1 - diferencia
                # As√≠: score alto = poca diferencia = malo (como MPRT)
                #      score bajo = mucha diferencia = bueno (como MPRT)
                score = 1.0 - normalized_distance
                
                scores.append(score)
            
            # Limpiar modelo aleatorizado de memoria
            del model_randomized
            torch.cuda.empty_cache() if torch.cuda.is_available() else None
            
            return np.array(scores)
    
    return AlternativeRandomizationMetric()

# Eval√∫a cada m√©todo XAI con varias m√©tricas de Quantus.
# Devuelve un diccionario: results[method][metric] = {mean, std, scores}.
def evaluate_methods(
    model: torch.nn.Module,
    explainer: XAIExplainer,
    x_batch: torch.Tensor,
    y_batch: torch.Tensor,
    methods: list[str],
    device: torch.device,
) -> Dict[str, Dict[str, Dict[str, float]]]:
    """
    Eval√∫a cada m√©todo XAI con varias m√©tricas de Quantus.
    Devuelve un diccionario: results[method][metric] = {mean, std, scores}.
    """
    model.eval()
    metrics = create_metrics()

    # Predicciones del modelo (para usar como clases objetivo)
    with torch.no_grad():
        logits = model(x_batch.to(device))
        preds = logits.argmax(dim=1)

    # Convertir datos a NumPy (manteniendo BCHW)
    x_np = to_numpy_bchw(x_batch)  # (B, C, H, W)
    y_np = y_batch.detach().cpu().numpy()

    results: Dict[str, Dict[str, Dict[str, float]]] = {}

    for method in methods:
        print(f"\n=== Evaluando m√©todo XAI: {method} ===")

        # 1) Atribuciones (mantenemos BCHW para coincidir con x_np)
        attr_bchw = compute_attributions(explainer, x_batch, preds, method)
        attr_np = to_numpy_bchw(attr_bchw)  # (B, C, H, W)

        method_results: Dict[str, Dict[str, float]] = {}

        # explain_func para m√©tricas que lo requieren (robustness, randomization)
        explain_fn = build_explain_func(explainer, method, device)

        for metric_name, metric in metrics.items():
            print(f" -> M√©trica: {metric_name}")
            try:
                # Robustez y aleatorizaci√≥n: usar explain_func (Quantus calcula a_batch internamente)
                if metric_name in {"robustness", "randomization"}:
                    # Logging adicional para randomization
                    if metric_name == "randomization":
                        print(f"    üîç Calculando randomization (MPRT) para {method}...")
                        print(f"       Esto puede tardar ya que aleatoriza par√°metros del modelo.")
                    
                    scores = metric(
                        model=model,
                        x_batch=x_np,
                        y_batch=y_np,
                        explain_func=explain_fn,
                        device=device,
                    )
                    
                    # Para randomization: verificar si MPRT devolvi√≥ valores constantes
                    # Si es as√≠, usar m√©trica alternativa m√°s sensible
                    if metric_name == "randomization":
                        # Extraer scores para verificar (manejar dict correctamente)
                        check_scores = None
                        if isinstance(scores, dict):
                            # Buscar la clave "scores" o cualquier valor que sea una lista/array num√©rico
                            if "scores" in scores:
                                check_scores = scores["scores"]
                            else:
                                # Buscar el primer valor que parezca una colecci√≥n num√©rica
                                for v in scores.values():
                                    if isinstance(v, (list, tuple, np.ndarray)):
                                        check_scores = v
                                        break
                        else:
                            check_scores = scores
                        
                        # Si encontramos scores, verificar si son constantes
                        if check_scores is not None:
                            try:
                                check_scores = np.array(check_scores, dtype=float).flatten()
                                valid_check = check_scores[np.isfinite(check_scores)]
                                
                                # Si todos los valores est√°n cerca de 1.0, usar m√©trica alternativa
                                if len(valid_check) > 0 and np.all(np.abs(valid_check - 1.0) < 0.01):
                                    print(f"    ‚ö†Ô∏è  MPRT devolvi√≥ valores constantes (~1.0) para todos los m√©todos")
                                    print(f"    üîÑ Cambiando a m√©trica alternativa basada en variabilidad con diferentes seeds...")
                                    print(f"       (Esta m√©trica mide qu√© tan diferentes son las explicaciones con diferentes seeds)")
                                    
                                    # Usar m√©trica alternativa
                                    alt_metric = create_alternative_randomization_metric()
                                    scores = alt_metric(
                                        model=model,
                                        x_batch=x_np,
                                        y_batch=y_np,
                                        explain_func=explain_fn,
                                        device=device,
                                    )
                                    print(f"    ‚úì M√©trica alternativa calculada (deber√≠a mostrar m√°s variaci√≥n entre m√©todos)")
                            except (ValueError, TypeError) as e:
                                # Si no podemos procesar los scores, usar m√©trica alternativa directamente
                                print(f"    ‚ö†Ô∏è  Error procesando scores de MPRT: {e}")
                                print(f"    üîÑ Usando m√©trica alternativa basada en variabilidad con diferentes seeds...")
                                alt_metric = create_alternative_randomization_metric()
                                scores = alt_metric(
                                    model=model,
                                    x_batch=x_np,
                                    y_batch=y_np,
                                    explain_func=explain_fn,
                                    device=device,
                                )
                                print(f"    ‚úì M√©trica alternativa calculada")
                        else:
                            # Si no encontramos scores, usar m√©trica alternativa directamente
                            print(f"    ‚ö†Ô∏è  No se pudieron extraer scores de MPRT (formato inesperado)")
                            print(f"    üîÑ Usando m√©trica alternativa basada en variabilidad con diferentes seeds...")
                            alt_metric = create_alternative_randomization_metric()
                            scores = alt_metric(
                                model=model,
                                x_batch=x_np,
                                y_batch=y_np,
                                explain_func=explain_fn,
                                device=device,
                            )
                            print(f"    ‚úì M√©trica alternativa calculada")
                else:
                    # Resto de m√©tricas: usar atribuciones precomputadas (a_batch)
                    scores = metric(
                        model=model,
                        x_batch=x_np,
                        y_batch=y_np,
                        a_batch=attr_np,
                        device=device,
                    )

                # Algunas m√©tricas (p.ej. randomization) pueden devolver un dict.
                if isinstance(scores, dict):
                    # Caso t√≠pico: clave 'scores'
                    if "scores" in scores:
                        raw_scores = scores["scores"]
                    else:
                        # Buscar el primer valor que parezca una colecci√≥n num√©rica
                        raw_scores = None
                        for v in scores.values():
                            if isinstance(v, (list, tuple, np.ndarray)):
                                raw_scores = v
                                break
                        if raw_scores is None:
                            raise TypeError(
                                f"Formato de salida de m√©trica '{metric_name}' no soportado: claves={list(scores.keys())}"
                            )
                else:
                    raw_scores = scores

                raw_scores = np.array(raw_scores, dtype=float).flatten()
                
                # Filtrar inf y nan antes de calcular estad√≠sticas
                valid_scores = raw_scores[np.isfinite(raw_scores)]  # isfinite = no inf y no nan
                
                if len(valid_scores) == 0:
                    # Si todos los valores son inf/nan, usar None
                    mean = None
                    std = None
                    print(f"    ‚ö†Ô∏è  Todos los valores son inf/nan, usando None")
                elif len(valid_scores) < len(raw_scores):
                    # Si hay algunos valores v√°lidos, calcular solo con ellos
                    mean = float(np.mean(valid_scores))
                    std = float(np.std(valid_scores))
                    invalid_count = len(raw_scores) - len(valid_scores)
                    print(f"    ‚ö†Ô∏è  {invalid_count}/{len(raw_scores)} valores inv√°lidos (inf/nan) filtrados")
                else:
                    # Todos los valores son v√°lidos
                    mean = float(np.mean(valid_scores))
                    std = float(np.std(valid_scores))
                
                # Convertir inf y nan a None para JSON
                mean_json = None if (mean is None or (mean is not None and (np.isinf(mean) or np.isnan(mean)))) else mean
                std_json = None if (std is None or (std is not None and (np.isinf(std) or np.isnan(std)))) else std
                
                # Convertir scores: inf -> None, nan -> None
                scores_list = []
                for s in raw_scores:
                    if np.isinf(s) or np.isnan(s):
                        scores_list.append(None)
                    else:
                        scores_list.append(float(s))

                method_results[metric_name] = {
                    "mean": mean_json,
                    "std": std_json,
                    "scores": scores_list,
                }
                
                # Print con manejo de inf/nan - mostrar valores reales o advertencia
                if mean_json is None:
                    if len(valid_scores) == 0:
                        print(f"    None (todos los valores son inf/nan)")
                    else:
                        print(f"    None (filtrados {len(raw_scores) - len(valid_scores)}/{len(raw_scores)} valores inv√°lidos)")
                elif std_json is None:
                    print(f"    {mean:.4f} ¬± None")
                else:
                    print(f"    {mean:.4f} ¬± {std:.4f}")
            except Exception as err:
                print(f"    ‚ö†Ô∏è Error evaluando {metric_name} para {method}: {err}")
                method_results[metric_name] = None

        results[method] = method_results

    return results

# Guarda los resultados en un archivo JSON.
def save_results(results: Dict, output_path: str) -> None:
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as file:
        json.dump(results, file, indent=2, ensure_ascii=False)
    print(f"\n‚úÖ Resultados guardados en {output_path}")


# ============================================================
#  main()
# ============================================================

# Funci√≥n principal
def main() -> None:
    args = parse_args()
    device = torch.device(args.device)
    
    # Establecer semilla para reproducibilidad
    set_global_seed(args.seed)

    print("=" * 60)
    print("  EVALUACI√ìN QUANTUS - RESNET18 XAI")
    print("=" * 60)
    print(f"Dataset: {args.dataset}")
    print(f"Dispositivo: {device}")
    print(f"M√©todos: {args.methods}")
    print(f"Muestras a evaluar: {args.num_samples}")
    print(f"Seed: {args.seed}")

    # Determinar n√∫mero de clases seg√∫n dataset
    meta_all = get_dataset_info()
    name_map = {"blood": "bloodmnist", "retina": "retinamnist", "breast": "breastmnist"}
    med_name = name_map[args.dataset]
    num_classes = int(meta_all[med_name]["n_classes"])

    # Determinar ruta del modelo
    if args.model_path is None:
        model_path = f"results/best_model_{args.dataset}.pth"
    else:
        model_path = args.model_path

    if not os.path.exists(model_path):
        raise FileNotFoundError(
            f"No se ha encontrado {model_path}. "
            f"Ejecuta primero: python train.py --dataset {args.dataset}"
        )

    # Modelo entrenado
    model = load_trained_model(model_path, device, num_classes=num_classes)

    # Datos de test
    datasets = load_datasets(args.data_dir, target_size=224)
    _, _, test_loader, _ = create_data_loaders(
        datasets=datasets,
        batch_size=args.batch_size,
        num_workers=0,
        num_classes=num_classes,
        dataset_name=args.dataset,
    )

    # Muestreo de ejemplos de test
    x_batch, y_batch = collect_samples(test_loader, args.num_samples, device)

    # Explainer XAI
    explainer = XAIExplainer(model, device, num_classes=num_classes)

    # Evaluaci√≥n
    results = evaluate_methods(model, explainer, x_batch, y_batch, args.methods, device)
    
    # A√±adir metadata al resultado
    results["metadata"] = {
        "dataset": args.dataset,
        "num_classes": num_classes,
        "num_samples": args.num_samples,
        "methods": args.methods,
    }
    
    # Determinar ruta de salida
    if args.output is None:
        output_path = f"outputs/quantus_metrics_{args.dataset}.json"
    else:
        output_path = args.output
    
    save_results(results, output_path)
    print(f"\n‚úÖ Resultados guardados en: {output_path}")


if __name__ == "__main__":
    main()

"""
Resumen
El script quantus_evaluation.py eval√∫a la explicabilidad de un modelo entrenado con varios m√©todos XAI (Grad-CAM, Grad-CAM++, Integrated Gradients y Saliency) usando las m√©tricas de Quantus.
1. Argumentos: lee los par√°metros de l√≠nea de comandos.
2. Datos: carga los datasets MedMNIST y crea un loader de test.
3. Muestreo: recoge un batch de muestras del conjunto de test.
4. Explainer: inicializa el objeto XAIExplainer.
5. Evaluaci√≥n: llama a evaluate_methods() para cada m√©todo XAI.
6. Guarda: guarda los resultados en un archivo JSON.

Resultado: un archivo JSON con los resultados de la evaluaci√≥n cuantitativa de la explicabilidad.
"""