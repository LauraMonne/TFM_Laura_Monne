{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline completo: Entrenamiento ResNet-18, XAI y Evaluación Quantitativa\n",
        "\n",
        "Este notebook unifica los tres pasos principales del TFM:\n",
        "\n",
        "1. **Entrenamiento de ResNet-18 sobre MedMNIST** (equivalente a `train.py`).\n",
        "2. **Generación de explicaciones XAI** con Grad-CAM / Grad-CAM++ / Integrated Gradients / Saliency (equivalente a `xai_explanations.py`).\n",
        "3. **Evaluación cuantitativa de la explicabilidad con Quantus** (equivalente a `quantus_evaluation.py`).\n",
        "\n",
        "La idea es poder ejecutar de principio a fin todo el pipeline desde un único notebook, con código comentado y secciones claras.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Configuración inicial\n",
        "\n",
        "En esta sección:\n",
        "- Comprobamos la versión de Python y PyTorch.\n",
        "- Configuramos el dispositivo (CPU / GPU).\n",
        "- Definimos rutas básicas y semilla de reproducibilidad.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dispositivo: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Ruta del proyecto\n",
        "PROJECT_DIR = Path('/home/TFM_Laura_Monne')\n",
        "RESULTS_DIR = PROJECT_DIR / 'results'\n",
        "DATA_DIR    = PROJECT_DIR / 'data'\n",
        "\n",
        "# Dispositivo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Dispositivo:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# Semilla global para reproducibilidad\n",
        "def set_global_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_global_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Entrenamiento / carga del modelo ResNet-18\n",
        "\n",
        "El **Objetivo** es **cargar y visualizar** los artefactos generados por los scripts ejecutados desde la **terminal** (`prepare_data.py`, `train.py`, `quick_test.py`).\n",
        "En la carpeta results/ tenemos los archivos `training_results.json`, `training_history.png`, `confusion_matrix.png`, `preds_test.npz`, `best_model.pth`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proyecto : \\home\\TFM_Laura_Monne\n",
            "Resultados: \\home\\TFM_Laura_Monne\\results\n",
            "Datos     : \\home\\TFM_Laura_Monne\\data\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "No existe \\home\\TFM_Laura_Monne. Clona el repo desde TERMINAL antes de usar el notebook.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mResultados:\u001b[39m\u001b[33m'\u001b[39m, RESULTS_DIR)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mDatos     :\u001b[39m\u001b[33m'\u001b[39m, DATA_DIR)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m PROJECT_DIR.exists(), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo existe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPROJECT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Clona el repo desde TERMINAL antes de usar el notebook.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m RESULTS_DIR.exists(), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo existe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRESULTS_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Entrena desde TERMINAL (python train.py) antes de usar el notebook.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mensure\u001b[39m(pkg_import_name, pip_name=\u001b[38;5;28;01mNone\u001b[39;00m):\n",
            "\u001b[31mAssertionError\u001b[39m: No existe \\home\\TFM_Laura_Monne. Clona el repo desde TERMINAL antes de usar el notebook."
          ]
        }
      ],
      "source": [
        "# Notebook para cargas y visualizar los resultados del entrenamiento de ResNet-18\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import subprocess\n",
        "import platform\n",
        "\n",
        "# Ruta del proyecto\n",
        "PROJECT_DIR = Path('/home/TFM_Laura_Monne')\n",
        "RESULTS_DIR = PROJECT_DIR / 'results'\n",
        "DATA_DIR    = PROJECT_DIR / 'data'\n",
        "\n",
        "print('Proyecto :', PROJECT_DIR)\n",
        "print('Resultados:', RESULTS_DIR)\n",
        "print('Datos     :', DATA_DIR)\n",
        "\n",
        "assert PROJECT_DIR.exists(), f\"No existe {PROJECT_DIR}. Clona el repo desde TERMINAL antes de usar el notebook.\"\n",
        "assert RESULTS_DIR.exists(), f\"No existe {RESULTS_DIR}. Entrena desde TERMINAL (python train.py) antes de usar el notebook.\"\n",
        "\n",
        "def ensure(pkg_import_name, pip_name=None):\n",
        "    \"\"\"Importa o instala con pip si falta.\"\"\"\n",
        "    try:\n",
        "        __import__(pkg_import_name)\n",
        "    except ImportError:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pip_name or pkg_import_name])\n",
        "\n",
        "# Dependencias mínimas para este notebook\n",
        "ensure(\"numpy\")\n",
        "ensure(\"pandas\")\n",
        "ensure(\"sklearn\", \"scikit-learn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "Aquí tenemos dos opciones:\n",
        "\n",
        "- **Opción A (rápida, recomendada)**: cargar el mejor modelo ya entrenado desde `results/best_model.pth` (si ya ejecutaste `train.py` o el notebook de entrenamiento).\n",
        "- **Opción B**: entrenar desde cero (puede tardar bastante; el código está resumido y se basa en `train.py`).\n",
        "\n",
        "Primero intentaremos cargar el modelo entrenado. Si no existe el checkpoint, puedes ejecutar el entrenamiento reducido desde este notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from prepare_data import load_datasets\n",
        "from train import Trainer, create_data_loaders\n",
        "from resnet18 import create_model\n",
        "\n",
        "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
        "RESULTS_DIR.mkdir(exist_ok=True)\n",
        "BEST_MODEL_PATH = RESULTS_DIR / \"best_model.pth\"\n",
        "\n",
        "print(\"Ruta de checkpoint esperada:\", BEST_MODEL_PATH)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Opción A: cargar modelo ya entrenado\n",
        "\n",
        "if BEST_MODEL_PATH.exists():\n",
        "    print(\"Encontrado checkpoint entrenado, cargando...\")\n",
        "    checkpoint = torch.load(BEST_MODEL_PATH, map_location=device)\n",
        "    model = create_model(num_classes=15)\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(\"Modelo cargado correctamente.\")\n",
        "else:\n",
        "    print(\"❌ No se ha encontrado best_model.pth. Ejecuta la celda de entrenamiento (Opción B).\")\n",
        "    model = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.C Visualización de curvas de entrenamiento\n",
        "\n",
        "Igual que en el *Notebook 1. Entrenamiento ResNet-18*, aquí mostramos las curvas de:\n",
        "\n",
        "- Pérdida y precisión por época (`training_history.png`, generada por `Trainer.plot_history()`).\n",
        "- (Opcional) Curvas guardadas por `make_report_assets.py` (`fig_training_curves.png`).\n",
        "\n",
        "Esta sección se ejecuta justo después del entrenamiento/carga del modelo para que puedas inspeccionar fácilmente cómo ha ido el entrenamiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "results_dir = Path(\"results\")\n",
        "\n",
        "fig_paths = [\n",
        "    results_dir / \"training_history.png\",\n",
        "    results_dir / \"fig_training_curves.png\",\n",
        "]\n",
        "\n",
        "for p in fig_paths:\n",
        "    if p.exists():\n",
        "        print(f\"Mostrando figura de entrenamiento: {p}\")\n",
        "        img = Image.open(p)\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"(Info) No se encontró la figura: {p}. Ejecuta el entrenamiento completo o 'make_report_assets.py' si la necesitas.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.B Entrenamiento reducido (opcional)\n",
        "\n",
        "Si **no** tienes un modelo entrenado, puedes ejecutar esta celda para entrenar una versión reducida (menos épocas) solo para comprobar que el pipeline funciona.\n",
        "\n",
        "> Nota: para los resultados finales del TFM se recomienda entrenar con `train.py` completo (120 épocas, early stopping, etc.). Aquí usamos muy pocas épocas para ir rápido.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenamiento reducido (ejecutar solo si model es None)\n",
        "\n",
        "if model is None:\n",
        "    print(\"Entrenando modelo reducido (pocas épocas, solo para prueba)...\")\n",
        "\n",
        "    # Config similar a train.py pero reducido\n",
        "    config = {\n",
        "        \"batch_size\": 64,\n",
        "        \"epochs\": 5,  # reducido\n",
        "        \"learning_rate\": 1e-3,\n",
        "        \"weight_decay\": 1e-4,\n",
        "        \"early_stopping_patience\": 3,\n",
        "        \"num_workers\": 4,\n",
        "        \"use_class_weights\": True,\n",
        "        \"grad_clip_norm\": 1.0,\n",
        "        \"num_classes\": 15,\n",
        "    }\n",
        "\n",
        "    # Cargar datasets y dataloaders\n",
        "    datasets = load_datasets(\"./data\", target_size=224)\n",
        "    train_loader, val_loader, test_loader, class_weights_vec = create_data_loaders(\n",
        "        datasets,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        num_workers=config[\"num_workers\"],\n",
        "        num_classes=config[\"num_classes\"],\n",
        "    )\n",
        "\n",
        "    model = create_model(num_classes=config[\"num_classes\"]).to(device)\n",
        "    trainer = Trainer(\n",
        "        model,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        test_loader,\n",
        "        device,\n",
        "        config,\n",
        "        class_weights=class_weights_vec if config[\"use_class_weights\"] else None,\n",
        "    )\n",
        "\n",
        "    history = trainer.train()\n",
        "    trainer.save_model(str(BEST_MODEL_PATH))\n",
        "    print(\"Checkpoint reducido guardado en:\", BEST_MODEL_PATH)\n",
        "else:\n",
        "    print(\"Ya hay un modelo cargado; se omite el entrenamiento reducido.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Generación de explicaciones XAI (Grad-CAM, Grad-CAM++, IG, Saliency)\n",
        "\n",
        "En esta sección reutilizamos la clase `XAIExplainer` de `xai_explanations.py` para:\n",
        "\n",
        "- Seleccionar unas pocas imágenes del conjunto de **test**.\n",
        "- Obtener la predicción del modelo.\n",
        "- Generar explicaciones con:\n",
        "  - Grad-CAM\n",
        "  - Grad-CAM++\n",
        "  - Integrated Gradients\n",
        "  - Saliency Maps\n",
        "- Mostrar las imágenes originales junto con sus mapas de explicabilidad.\n",
        "\n",
        "Esto corresponde funcionalmente al script `xai_explanations.py`, pero aquí lo hacemos de forma interactiva.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from data_utils import create_data_loaders_fixed\n",
        "from xai_explanations import XAIExplainer\n",
        "\n",
        "# Asegurarnos de tener un modelo entrenado/cargado\n",
        "aassert_msg = \"El modelo es None. Asegúrate de haber cargado o entrenado en la sección 1.\"\n",
        "assert model is not None, aassert_msg\n",
        "\n",
        "# DataLoaders con el collate robusto a canales\n",
        "datasets = load_datasets(\"./data\", target_size=224)\n",
        "_, _, test_loader = create_data_loaders_fixed(\n",
        "    datasets=datasets,\n",
        "    batch_size=1,\n",
        "    num_workers=0,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "explainer = XAIExplainer(model, device, num_classes=15)\n",
        "print(\"XAIExplainer inicializado.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Número de ejemplos que queremos visualizar\n",
        "NUM_EXAMPLES = 3\n",
        "\n",
        "examples = []\n",
        "for idx, (data, target) in enumerate(test_loader):\n",
        "    if idx >= NUM_EXAMPLES:\n",
        "        break\n",
        "    examples.append((data.to(device), target.to(device)))\n",
        "\n",
        "print(f\"Tomados {len(examples)} ejemplos del conjunto de test.\")\n",
        "\n",
        "for i, (x, y_true) in enumerate(examples):\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "        pred_class = int(logits.argmax(dim=1).item())\n",
        "        true_class = int(y_true.item())\n",
        "    print(f\"Ejemplo {i}: true={true_class}, pred={pred_class}\")\n",
        "\n",
        "    # Generar todas las explicaciones (reutiliza la interfaz ya existente)\n",
        "    res = explainer.generate_all_explanations(\n",
        "        input_tensor=x,\n",
        "        pred_class=pred_class,\n",
        "        image_idx=i,\n",
        "    )\n",
        "\n",
        "print(\"Mapas XAI guardados en carpeta 'outputs/' (gradcam, gradcampp, integrated_gradients, saliency).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualización de curvas de entrenamiento\n",
        "\n",
        "En esta sección mostramos, si existen, las figuras generadas durante el entrenamiento:\n",
        "\n",
        "- `results/training_history.png` (generada por `Trainer.plot_history()` en `train.py`).\n",
        "- `results/fig_training_curves.png` (generada por `make_report_assets.py`).\n",
        "\n",
        "La celda de abajo **no falla** si los ficheros aún no existen: simplemente indica cuáles faltan.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "fig_paths = [\n",
        "    Path(\"results\") / \"training_history.png\",\n",
        "    Path(\"results\") / \"fig_training_curves.png\",\n",
        "]\n",
        "\n",
        "for p in fig_paths:\n",
        "    if p.exists():\n",
        "        print(f\"Mostrando figura: {p}\")\n",
        "        img = Image.open(p)\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"(Info) No se encontró la figura: {p}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Evaluación cuantitativa de la explicabilidad con Quantus\n",
        "\n",
        "Finalmente, evaluamos de forma **cuantitativa** las explicaciones generadas, usando **Quantus**.\n",
        "\n",
        "En lugar de llamar a `quantus_evaluation.py` desde consola, reutilizamos su lógica simplificada directamente aquí:\n",
        "\n",
        "- Tomamos un pequeño lote del conjunto de test (por ejemplo, 30 imágenes).\n",
        "- Generamos las atribuciones para cada método XAI.\n",
        "- Calculamos las métricas de Quantus:\n",
        "  - FaithfulnessCorrelation\n",
        "  - AvgSensitivity\n",
        "  - Complexity / Entropy\n",
        "  - MPRT / ModelParameterRandomisation\n",
        "  - RegionPerturbation\n",
        "- Guardamos los resultados en un JSON para poder analizarlos o introducirlos en la memoria.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from quantus_evaluation import (\n",
        "    collect_samples,\n",
        "    evaluate_methods,\n",
        "    save_results,\n",
        ")\n",
        "\n",
        "# Número de muestras para la evaluación cuantitativa (puedes subirlo si quieres más robustez)\n",
        "NUM_SAMPLES_QUANTUS = 30\n",
        "\n",
        "# Volvemos a crear un loader de test (batch_size=1 para recolectar muestras fácilmente)\n",
        "_, _, test_loader_q = create_data_loaders_fixed(\n",
        "    datasets=datasets,\n",
        "    batch_size=1,\n",
        "    num_workers=0,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "x_batch, y_batch = collect_samples(test_loader_q, NUM_SAMPLES_QUANTUS, device)\n",
        "print(\"Forma de x_batch:\", x_batch.shape)\n",
        "print(\"Forma de y_batch:\", y_batch.shape)\n",
        "\n",
        "methods_to_eval = [\"gradcam\", \"gradcampp\", \"integrated_gradients\", \"saliency\"]\n",
        "\n",
        "results = evaluate_methods(\n",
        "    model=model,\n",
        "    explainer=explainer,\n",
        "    x_batch=x_batch,\n",
        "    y_batch=y_batch,\n",
        "    methods=methods_to_eval,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "OUTPUT_QUANTUS = PROJECT_ROOT / \"outputs\" / \"quantus_metrics_notebook.json\"\n",
        "save_results(results, str(OUTPUT_QUANTUS))\n",
        "\n",
        "results\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
