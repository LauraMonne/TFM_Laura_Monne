# ğŸ“Š GuÃ­a de Explicabilidad (XAI) - ResNet-18 MedMNIST

## ğŸ“‹ DescripciÃ³n

Este script implementa mÃ©todos de explicabilidad segÃºn la memoria del TFM, aplicando diferentes tÃ©cnicas XAI y evaluÃ¡ndolas cuantitativamente con Quantus.

## ğŸ”§ InstalaciÃ³n

### 1. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 2. Verificar instalaciÃ³n

```bash
python -c "import grad_cam; import captum; import quantus; print('âœ… Todas las librerÃ­as instaladas')"
```

## ğŸš€ Uso

### Ejecutar explicabilidad completa

```bash
python xai_explanations.py
```

### ConfiguraciÃ³n

El script estÃ¡ configurado para:
- Cargar el modelo desde `results/best_model.pth`
- Generar explicaciones para 20 muestras por defecto
- Guardar resultados en `outputs/`

### Cambiar nÃºmero de muestras

Editar lÃ­nea 466 en `xai_explanations.py`:
```python
num_samples = 20  # Cambiar a nÃºmero deseado
```

## ğŸ“Š MÃ©todos Implementados

### 1. Grad-CAM
- **LibrerÃ­a**: pytorch-grad-cam
- **DescripciÃ³n**: Identifica regiones importantes usando gradientes de la Ãºltima capa convolucional
- **Salida**: `outputs/gradcam/`

### 2. Grad-CAM++
- **LibrerÃ­a**: pytorch-grad-cam
- **DescripciÃ³n**: VersiÃ³n mejorada de Grad-CAM con mejor localizaciÃ³n
- **Salida**: `outputs/gradcampp/`

### 3. Integrated Gradients (IG)
- **LibrerÃ­a**: Captum
- **DescripciÃ³n**: Calcula contribuciÃ³n de pÃ­xeles a lo largo de un trayecto interpolado
- **Salida**: `outputs/integrated_gradients/`

### 4. Saliency Maps (Vanilla Saliency)
- **LibrerÃ­a**: Captum
- **DescripciÃ³n**: Muestra pÃ­xeles con mayor impacto directo sobre la predicciÃ³n
- **Salida**: `outputs/saliency/`

## ğŸ“ˆ EvaluaciÃ³n Cuantitativa (Quantus)

### MÃ©tricas Evaluadas

1. **Faithfulness (Fidelidad)**
   - MÃ©trica: Faithfulness Correlation
   - Mide si la explicaciÃ³n refleja el comportamiento interno del modelo
   - Rango: [-1, 1] (mayor es mejor)

2. **Robustness (Robustez)**
   - MÃ©trica: Average Sensitivity
   - EvalÃºa estabilidad ante perturbaciones leves
   - Rango: [0, âˆ] (menor es mejor)

3. **Complexity (Complejidad)**
   - MÃ©trica: Entropy
   - Estima simplicidad de la explicaciÃ³n
   - Rango: [0, âˆ] (menor es mejor para interpretabilidad)

4. **Randomization (AleatorizaciÃ³n)**
   - MÃ©trica: Randomization Test
   - Mide dependencia de la explicaciÃ³n respecto a semillas aleatorias
   - Rango: [-1, 1] (mayor es mejor)

5. **Localization (LocalizaciÃ³n)**
   - MÃ©trica: Region Perturbation
   - Determina precisiÃ³n espacial de la explicaciÃ³n
   - Rango: [0, 1] (mayor es mejor)

### Resultados

Los resultados de Quantus se guardan en:
- `outputs/quantus_evaluation.json`

Formato:
```json
{
  "gradcam": {
    "faithfulness": {"mean": 0.75, "std": 0.12},
    "robustness": {"mean": 0.15, "std": 0.05},
    "complexity": {"mean": 2.3, "std": 0.4},
    "randomization": {"mean": 0.82, "std": 0.08},
    "localization": {"mean": 0.68, "std": 0.15}
  },
  "integrated_gradients": {...},
  "saliency": {...}
}
```

## ğŸ“ Estructura de Salida

```
outputs/
â”œâ”€â”€ gradcam/                    # Mapas Grad-CAM
â”‚   â””â”€â”€ img_*_class_*.png
â”œâ”€â”€ gradcampp/                  # Mapas Grad-CAM++
â”‚   â””â”€â”€ img_*_class_*.png
â”œâ”€â”€ integrated_gradients/       # Mapas Integrated Gradients
â”‚   â””â”€â”€ img_*_class_*.png
â”œâ”€â”€ saliency/                   # Mapas Saliency
â”‚   â””â”€â”€ img_*_class_*.png
â”œâ”€â”€ explanations_results.json   # Metadatos de explicaciones
â””â”€â”€ quantus_evaluation.json     # Resultados de evaluaciÃ³n cuantitativa
```

## ğŸ› SoluciÃ³n de Problemas

### Error: "Modelo no encontrado"
- **Causa**: No se ha entrenado el modelo
- **SoluciÃ³n**: Ejecutar `python train.py` primero

### Error: "Grad-CAM no disponible"
- **Causa**: LibrerÃ­a no instalada
- **SoluciÃ³n**: `pip install grad-cam`

### Error: "Captum no disponible"
- **Causa**: LibrerÃ­a no instalada
- **SoluciÃ³n**: `pip install captum`

### Error: "Quantus no disponible"
- **Causa**: LibrerÃ­a no instalada
- **SoluciÃ³n**: `pip install quantus`

### Error en evaluaciÃ³n Quantus
- **Causa**: Puede ser por memoria insuficiente o formato de datos
- **SoluciÃ³n**: Reducir `num_samples` o verificar formato de imÃ¡genes

## ğŸ“š Referencias

- [PyTorch Grad-CAM](https://github.com/jacobgil/pytorch-grad-cam)
- [Captum](https://captum.ai/)
- [Quantus](https://github.com/understandable-machine-intelligence-lab/Quantus)
- [Grad-CAM Paper](https://arxiv.org/abs/1610.02391)
- [Integrated Gradients Paper](https://arxiv.org/abs/1703.01365)

## ğŸ“ Notas

- El modelo ResNet-18 adaptativo maneja automÃ¡ticamente imÃ¡genes RGB y escala de grises
- Las explicaciones se generan para la clase predicha por el modelo
- La evaluaciÃ³n con Quantus puede tardar varios minutos segÃºn el nÃºmero de muestras
- Se recomienda usar GPU para acelerar la generaciÃ³n de explicaciones

## ğŸ”„ PrÃ³ximos Pasos

1. Analizar resultados de Quantus para comparar mÃ©todos
2. Generar visualizaciones comparativas
3. Incorporar resultados en la memoria del TFM
4. Optimizar parÃ¡metros de evaluaciÃ³n segÃºn necesidades

