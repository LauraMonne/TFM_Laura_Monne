# ğŸ“Š GuÃ­a de Explicabilidad (XAI) - ResNet-18 MedMNIST

## ğŸ“‹ DescripciÃ³n

Este script implementa los mÃ©todos de explicabilidad descritos en la memoria del TFM, generando mapas XAI (Grad-CAM, Grad-CAM++, Integrated Gradients y Saliency) y dejando preparados los artefactos necesarios para su evaluaciÃ³n cuantitativa con Quantus en un notebook independiente.

## ğŸ”§ InstalaciÃ³n

### 1. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 2. Verificar instalaciÃ³n

```bash
python -c "import pytorch_grad_cam; from captum.attr import IntegratedGradients, Saliency; import quantus; print('âœ… Todas las librerÃ­as instaladas')"
```

## ğŸš€ Uso

### Ejecutar explicabilidad completa

```bash
python xai_explanations.py
```

### ConfiguraciÃ³n

El script estÃ¡ configurado para:

- Cargar el modelo desde `results/best_model.pth`
- Generar explicaciones para un mÃ¡ximo de **500 muestras** del conjunto de test,
  estratificadas por dataset:
  - 300 de BloodMNIST
  - 150 de RetinaMNIST
  - 50 de BreastMNIST
- Guardar resultados en `outputs/`

## ğŸ“Š MÃ©todos Implementados

### 1. Grad-CAM
- **LibrerÃ­a**: pytorch-grad-cam
- **DescripciÃ³n**: Identifica regiones importantes usando gradientes de la Ãºltima capa convolucional
- **Salida**: `outputs/gradcam/`

### 2. Grad-CAM++
- **LibrerÃ­a**: pytorch-grad-cam
- **DescripciÃ³n**: VersiÃ³n mejorada de Grad-CAM con mejor localizaciÃ³n
- **Salida**: `outputs/gradcampp/`

### 3. Integrated Gradients (IG)
- **LibrerÃ­a**: Captum
- **DescripciÃ³n**: Calcula contribuciÃ³n de pÃ­xeles a lo largo de un trayecto interpolado
- **Salida**: `outputs/integrated_gradients/`

### 4. Saliency Maps (Vanilla Saliency)
- **LibrerÃ­a**: Captum
- **DescripciÃ³n**: Muestra pÃ­xeles con mayor impacto directo sobre la predicciÃ³n
- **Salida**: `outputs/saliency/`

## ğŸ“ˆ EvaluaciÃ³n Cuantitativa (Quantus)

**Nota importante**: El script actual NO ejecuta la evaluaciÃ³n cuantitativa automÃ¡ticamente. La funciÃ³n `evaluate_with_quantus_stub()` solo informa sobre la disponibilidad de Quantus. La evaluaciÃ³n cuantitativa debe realizarse en un notebook dedicado usando los mapas generados por este script.

### MÃ©tricas a Evaluar (en notebook separado)

Para evaluar los mapas generados, puedes usar Quantus en un notebook con las siguientes mÃ©tricas:

1. **Faithfulness (Fidelidad)**
   - MÃ©trica: Faithfulness Correlation
   - Mide si la explicaciÃ³n refleja el comportamiento interno del modelo
   - Rango: [-1, 1] (mayor es mejor)

2. **Robustness (Robustez)**
   - MÃ©trica: Average Sensitivity
   - EvalÃºa estabilidad ante perturbaciones leves
   - Rango: [0, âˆ] (menor es mejor)

3. **Complexity (Complejidad)**
   - MÃ©trica: Entropy
   - Estima simplicidad de la explicaciÃ³n
   - Rango: [0, âˆ] (menor es mejor para interpretabilidad)

4. **Randomization (AleatorizaciÃ³n)**
   - MÃ©trica: Randomization Test
   - Mide dependencia de la explicaciÃ³n respecto a semillas aleatorias
   - Rango: [-1, 1] (mayor es mejor)

5. **Localization (LocalizaciÃ³n)**
   - MÃ©trica: Region Perturbation
   - Determina precisiÃ³n espacial de la explicaciÃ³n
   - Rango: [0, 1] (mayor es mejor)

### CÃ³mo Evaluar con Quantus

1. Ejecutar este script para generar los mapas: `python xai_explanations.py`
2. Crear un notebook Jupyter para la evaluaciÃ³n cuantitativa
3. Cargar los mapas generados desde `outputs/`
4. Usar la librerÃ­a Quantus para evaluar cada mÃ©todo segÃºn las 5 dimensiones

**Ejemplo de evaluaciÃ³n** (en notebook):
```python
import quantus
# Cargar mapas generados
# Evaluar con las mÃ©tricas definidas
```

## ğŸ“ Estructura de Salida

```
outputs/
â”œâ”€â”€ gradcam/                    # Mapas Grad-CAM
â”‚   â””â”€â”€ img_*_class_*.png
â”œâ”€â”€ gradcampp/                  # Mapas Grad-CAM++
â”‚   â””â”€â”€ img_*_class_*.png
â”œâ”€â”€ integrated_gradients/       # Mapas Integrated Gradients
â”‚   â””â”€â”€ img_*_class_*.png
â”œâ”€â”€ saliency/                   # Mapas Saliency
â”‚   â””â”€â”€ img_*_class_*.png
â””â”€â”€ explanations_results.json   # Metadatos de explicaciones
```

## ğŸ› SoluciÃ³n de Problemas

### Error: "Modelo no encontrado"
- **Causa**: No se ha entrenado el modelo
- **SoluciÃ³n**: Ejecutar `python train.py` primero

### Error: "Grad-CAM no disponible"
- **Causa**: LibrerÃ­a no instalada
- **SoluciÃ³n**: `pip install grad-cam`

### Error: "Captum no disponible"
- **Causa**: LibrerÃ­a no instalada
- **SoluciÃ³n**: `pip install captum`

### Error: "Quantus no disponible"
- **Causa**: LibrerÃ­a no instalada
- **SoluciÃ³n**: `pip install quantus`

### Error: "too many indices for tensor of dimension 1"
- **Causa**: Problema con el callback de Grad-CAM (ya corregido en versiÃ³n actual)
- **SoluciÃ³n**: AsegÃºrate de tener la versiÃ³n mÃ¡s reciente del script desde GitHub

### Error en evaluaciÃ³n Quantus
- **Nota**: La evaluaciÃ³n cuantitativa no se ejecuta automÃ¡ticamente en este script
- **SoluciÃ³n**: Realizar la evaluaciÃ³n en un notebook dedicado usando los mapas generados

## ğŸ“š Referencias

- [PyTorch Grad-CAM](https://github.com/jacobgil/pytorch-grad-cam)
- [Captum](https://captum.ai/)
- [Quantus](https://github.com/understandable-machine-intelligence-lab/Quantus)
- [Grad-CAM Paper](https://arxiv.org/abs/1610.02391)
- [Integrated Gradients Paper](https://arxiv.org/abs/1703.01365)

## ğŸ“ Notas

- El modelo ResNet-18 adaptativo maneja automÃ¡ticamente imÃ¡genes RGB y escala de grises
- Las explicaciones se generan para la clase predicha por el modelo
- **La evaluaciÃ³n cuantitativa con Quantus NO se ejecuta automÃ¡ticamente** en este script
  - El script solo genera los mapas de explicabilidad
  - La evaluaciÃ³n cuantitativa debe hacerse en un notebook dedicado
- Se recomienda usar GPU para acelerar la generaciÃ³n de explicaciones
- El callback de Grad-CAM estÃ¡ corregido para manejar correctamente tensores 1D y 2D

## ğŸ”„ PrÃ³ximos Pasos

1. **Ejecutar el script**: `python xai_explanations.py` para generar mapas
2. **Crear notebook de evaluaciÃ³n**: Implementar evaluaciÃ³n cuantitativa con Quantus
3. Analizar resultados de Quantus para comparar mÃ©todos
4. Generar visualizaciones comparativas
5. Incorporar resultados en la memoria del TFM

