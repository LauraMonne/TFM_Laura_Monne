# Evaluaci贸n cuantitativa de la explicabilidad (Quantus)

Este documento explica c贸mo ejecutar el script `quantus_evaluation.py` para medir la calidad de las explicaciones (Grad-CAM, Grad-CAM++, Integrated Gradients y Saliency) sobre modelos entrenados de manera independiente por dataset.

## Requisitos previos

1. Haber entrenado el modelo (`python train.py`) y disponer de los checkpoints:
- results/best_model_blood.pth
- results/best_model_retina.pth
- results/best_model_breast.pth
2. Tener los datasets MedMNIST preparados en la carpeta data/ (BloodMNIST, RetinaMNIST y BreastMNIST).
3. Tener instaladas las dependencias del proyecto:
  ```bash
  pip install -r requirements.txt
  pip install quantus
  ```

##  Ejecuci贸n del script

La evaluaci贸n cuantitativa se realiza por dataset, de forma coherente con el entrenamiento de tres modelos independientes.
```bash
python quantus_evaluation.py \
    --dataset blood \
    --model_path results/best_model_blood.pth \
    --data_dir ./data \
    --num_samples 30

python quantus_evaluation.py \
    --dataset retina \
    --model_path results/best_model_retina.pth \
    --data_dir ./data \
    --num_samples 30

python quantus_evaluation.py \
    --dataset breast \
    --model_path results/best_model_breast.pth \
    --data_dir ./data \
    --num_samples 30
```

Par谩metros principales:
| Flag | Descripci贸n | Default |
|------|-------------|---------|
| `--dataset` | Dataset a evaluar (`blood`, `retina`, `breast`) | Obligatorio |
| `--model_path` | Ruta al checkpoint del modelo | Obligatorio |
| `--num_samples` | N潞 de im谩genes del test utilizadas para generar atribuciones | 30 |
| `--sample_strategy` | Muestreo del test: `first` (primeras N) o `reservoir` (aleatorio uniforme) | `reservoir` |
| `--seed` | Semilla para muestreo aleatorio | 42 |
| `--target` | Etiquetas objetivo para m茅tricas: `pred` (predicha) o `true` (real) | `pred` |
| `--methods` | M茅todos XAI (`gradcam`, `gradcampp`, `integrated_gradients`, `saliency`) | Todos |
| `--device` | `cuda` o `cpu` | Detectado autom谩ticamente |

## M茅tricas de explicabilidad evaluadas

| Dimensi贸n | M茅trica (Quantus) | Descripci贸n resumida |
|-----------|-------------------|----------------------|
| Fidelidad | `FaithfulnessCorrelation` | Correlaci贸n entre atribuci贸n y logits del modelo. |
| Robustez  | `AvgSensitivity` | Sensibilidad a perturbaciones leves en la entrada. |
| Complejidad | `Entropy` | Simplicidad / dispersi贸n de la explicaci贸n. |
| Aleatorizaci贸n | `ModelParameterRandomisation` | Comprueba dependencia respecto a pesos del modelo. |
| Localizaci贸n | `RegionPerturbation` (proxy) | Eval煤a qu茅 ocurre al anular regiones de alta atribuci贸n. |

**Nota de configuraci贸n (rendimiento):** el script reduce el coste computacional con
`nr_runs=30` en Faithfulness, `regions_evaluation=30` en Localizaci贸n y en Randomization
usa `skip_layers=True` (comparaci贸n solo original vs totalmente randomizado). Ajusta estos
valores en `quantus_evaluation.py` si necesitas mayor fidelidad estad铆stica.

## Salida

El script genera `outputs/quantus_metrics_<dataset>.json`.

Estos ficheros son posteriormente procesados en el notebook `quantus_eval.ipynb` para generar:
- `quantus_table_raw_<dataset>.csv`
- `quantus_table_normalized_<dataset>.csv`
- `quantus_radar_<dataset>.png`

Estos resultados se utilizan directamente en el Cap铆tulo 4 (Resultados) y se discuten en el Cap铆tulo 5 (Discusi贸n) del TFM.


## Flujo recomendado

1. Entrenar los modelos
```bash
python train.py --dataset blood
python train.py --dataset retina
python train.py --dataset breast
```
2. Generar explicaciones visuales (`xai_explanations.py`).
3. Ejecutar la evaluaci贸n cuantitativa con Quantus (por dataset).
4. Analizar los resultados en `notebooks/quantus_eval.ipynb`.

Con este flujo se cumple la secci贸n 3.8 de la memoria, aportando m茅tricas objetivas de fidelidad, robustez, complejidad, aleatorizaci贸n y localizaci贸n para los m茅todos de explicabilidad. 
