# üìà Evaluaci√≥n cuantitativa de la explicabilidad (Quantus)

Este documento explica c√≥mo ejecutar el script `quantus_evaluation.py` para medir la calidad de las explicaciones (Grad-CAM, Grad-CAM++, Integrated Gradients y Saliency) seg√∫n las 5 dimensiones descritas en la memoria del TFM.

## ‚úÖ Requisitos previos

- Haber entrenado el modelo (`python train.py`) y disponer de `results/best_model.pth`.
- Haber generado las explicaciones base si se necesita comparar visualmente (`python xai_explanations.py`).
- Tener instaladas las dependencias:
  ```bash
  pip install -r requirements.txt
  pip install quantus
  ```

## üöÄ Ejecuci√≥n del script

Desde la ra√≠z del proyecto:
```bash
python quantus_evaluation.py \
    --model_path results/best_model.pth \
    --data_dir ./data \
    --num_samples 30 \
    --methods gradcam integrated_gradients saliency
```

Par√°metros principales:
| Flag | Descripci√≥n | Default |
|------|-------------|---------|
| `--num_samples` | N¬∫ de im√°genes del test utilizadas para generar atribuciones | 30 |
| `--methods` | M√©todos XAI a evaluar (`gradcam`, `gradcampp`, `integrated_gradients`, `saliency`) | `gradcam ig saliency` |
| `--output` | Ruta del JSON con resultados | `outputs/quantus_metrics.json` |
| `--device` | `cuda` o `cpu` | Detectado autom√°ticamente |

## üß† Qu√© calcula cada m√©trica

| Dimensi√≥n | M√©trica (Quantus) | Descripci√≥n resumida |
|-----------|-------------------|----------------------|
| Fidelidad | `FaithfulnessCorrelation` | Correlaci√≥n entre atribuci√≥n y logits del modelo. |
| Robustez  | `AvgSensitivity` | Sensibilidad a perturbaciones leves en la entrada. |
| Complejidad | `Entropy` | Simplicidad / dispersi√≥n de la explicaci√≥n. |
| Aleatorizaci√≥n | `ModelParameterRandomisation` | Comprueba dependencia respecto a pesos del modelo. |
| Localizaci√≥n | `RegionPerturbation` (proxy) | Eval√∫a qu√© ocurre al anular regiones de alta atribuci√≥n. |

**Nota**: Si se dispone de m√°scaras anat√≥micas/ROI, se puede extender el script para usar la m√©trica `AttributionLocalisation` de Quantus con supervisi√≥n.

## üìÅ Salida

El script genera `outputs/quantus_metrics.json` con el siguiente formato:
```json
{
  "gradcam": {
    "faithfulness": {"mean": 0.74, "std": 0.11},
    "robustness": {"mean": 0.18, "std": 0.05},
    "complexity": {"mean": 2.10, "std": 0.30},
    "randomization": {"mean": 0.80, "std": 0.07},
    "localization": {"mean": 0.62, "std": 0.12}
  },
  "integrated_gradients": {...},
  "saliency": {...}
}
```

Estos resultados pueden exportarse a tablas o gr√°ficos para la memoria del TFM.

## üõ†Ô∏è Consejos pr√°cticos

- Reducir `--num_samples` si la GPU/CPU no dispone de suficiente memoria.
- Usar `--methods gradcam gradcampp` para comparar ambas variantes.
- Si se ejecuta en CPU, considerar `--num_samples 10` para pruebas r√°pidas.
- Para an√°lisis avanzados, trasladar el pipeline a un notebook y visualizar las distribuciones de cada m√©trica.

## üîÑ Flujo recomendado

1. Entrenar modelo (`train.py`).
2. Generar mapas (`xai_explanations.py`).
3. Ejecutar evaluaci√≥n cuantitativa (`quantus_evaluation.py`).
4. Analizar `outputs/quantus_metrics.json` y resumir en la memoria.

Con este flujo se cumple la secci√≥n 3.8 de la memoria, aportando m√©tricas objetivas de fidelidad, robustez, complejidad, aleatorizaci√≥n y localizaci√≥n para los m√©todos de explicabilidad. 

