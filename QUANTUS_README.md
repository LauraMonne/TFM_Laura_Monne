# üìà Evaluaci√≥n cuantitativa de la explicabilidad (Quantus)

Este documento explica c√≥mo ejecutar el script `quantus_evaluation.py` para medir la calidad de las explicaciones (Grad-CAM, Grad-CAM++, Integrated Gradients y Saliency) sobre modelos entrenados de manera independiente por dataset.

## ‚úÖ Requisitos previos

1. Haber entrenado el modelo (`python train.py`) y disponer de los checkpoints:
- results/best_model_blood.pth
- results/best_model_retina.pth
- results/best_model_breast.pth
2. Tener los datasets MedMNIST preparados en la carpeta data/ (BloodMNIST, RetinaMNIST y BreastMNIST).
3. Tener instaladas las dependencias del proyecto:
  ```bash
  pip install -r requirements.txt
  pip install quantus
  ```

## üöÄ Ejecuci√≥n del script

La evaluaci√≥n cuantitativa se realiza por dataset, de forma coherente con el entrenamiento de tres modelos independientes.
```bash
python quantus_evaluation.py \
    --dataset blood \
    --model_path results/best_model_blood.pth \
    --data_dir ./data \
    --num_samples 30

python quantus_evaluation.py \
    --dataset retina \
    --model_path results/best_model_retina.pth \
    --data_dir ./data \
    --num_samples 30

python quantus_evaluation.py \
    --dataset breast \
    --model_path results/best_model_breast.pth \
    --data_dir ./data \
    --num_samples 30
```

Par√°metros principales:
| Flag | Descripci√≥n | Default |
|------|-------------|---------|
| `--dataset` | Dataset a evaluar (`blood`, `retina`, `breast`) | Obligatorio |
| `--model_path | Ruta al checkpoint del modelo | 30 |
| `--num_samples` | N¬∫ de im√°genes del test utilizadas para generar atribuciones | Obligatorio |
| `--methods` | M√©todos XAI (`gradcam`, `gradcampp`, `integrated_gradients`, `saliency`) | Todos |
| `--device` | `cuda` o `cpu` | Detectado autom√°ticamente |

## M√©tricas de explicabilidad evaluadas

| Dimensi√≥n | M√©trica (Quantus) | Descripci√≥n resumida |
|-----------|-------------------|----------------------|
| Fidelidad | `FaithfulnessCorrelation` | Correlaci√≥n entre atribuci√≥n y logits del modelo. |
| Robustez  | `AvgSensitivity` | Sensibilidad a perturbaciones leves en la entrada. |
| Complejidad | `Entropy` | Simplicidad / dispersi√≥n de la explicaci√≥n. |
| Aleatorizaci√≥n | `ModelParameterRandomisation` | Comprueba dependencia respecto a pesos del modelo. |
| Localizaci√≥n | `RegionPerturbation` (proxy) | Eval√∫a qu√© ocurre al anular regiones de alta atribuci√≥n. |

## Salida

El script genera `outputs/quantus_metrics_<dataset>.json`.

Estos ficheros son posteriormente procesados en el notebook `quantus_eval.ipynb` para generar:
- `quantus_table_raw_<dataset>.csv`
- `quantus_table_normalized_<dataset>.csv`
- `quantus_radar_<dataset>.png`

Estos resultados se utilizan directamente en el Cap√≠tulo 4 (Resultados) y se discuten en el Cap√≠tulo 5 (Discusi√≥n) del TFM.


## Flujo recomendado

1. Entrenar los modelos
```bash
python train.py --dataset blood
python train.py --dataset retina
python train.py --dataset breast
```
2. Generar explicaciones visuales (`xai_explanations.py`).
3. Ejecutar la evaluaci√≥n cuantitativa con Quantus (por dataset).
4. Analizar los resultados en `notebooks/quantus_eval.ipynb`.

Con este flujo se cumple la secci√≥n 3.8 de la memoria, aportando m√©tricas objetivas de fidelidad, robustez, complejidad, aleatorizaci√≥n y localizaci√≥n para los m√©todos de explicabilidad. 

